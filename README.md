# Linear Regression in Python

**[1D Linear Regression](https://github.com/nkuhta/Linear-Regression-Python/blob/master/linear_1D.py)**  
&ensp; Analytical solution for 1D linear regression in vectorized form.  
**[Moore's Law](https://github.com/nkuhta/Linear-Regression-Python/blob/master/moore.py)**  
&ensp; Using linear regression for exponentially growing data.  
**[2D Linear Regression](https://github.com/nkuhta/Linear-Regression-Python/blob/master/linear_2D.py)**  
&ensp; Calculate weights and constant coefficients for 2D linear system.  
**[Polynomial Regression](https://github.com/nkuhta/Linear-Regression-Python/blob/master/polynomial_regression.py)**  
&ensp; Quadradic polynomial regression analysis.  
**[Blood Pressure (2D Regression)](https://github.com/nkuhta/Linear-Regression-Python/blob/master/systolic.py)**  
&ensp; Predict systolic blood pressure from age and weight.  

#  Regularization 
**[L2 Regularization](https://github.com/nkuhta/Linear-Regression-Python/blob/master/L2_regularization.py)**  
&ensp; Using L2 regularization to find better fit for linear data with outliers by encouraging smaller weights.   
**[L1 Regularization](https://github.com/nkuhta/Linear-Regression-Python/blob/master/L1_regularization.py)**  
&ensp; Using L1 regularization, absolute coefficient value cost function term, to encourage sparse coefficients.  

#  Gradient Descent
**[Gradient Descent](https://github.com/nkuhta/Linear-Regression-Python/blob/master/gradient_descent.py)**  
&ensp; Gradient descent method for singular feature matrices. 

##  References
1.  **Linear Regression in Python** - Udemy   
	https://www.udemy.com/data-science-linear-regression-in-python
